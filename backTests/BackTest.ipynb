{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66329261-9a7b-4a54-b26d-44ddefb32c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f208549d-81ba-4ba8-b579-cdf3ed4e035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.6-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82c0e85c-6066-4e22-9ec6-5e72bb9e4623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500_30bps.csv')\n",
    "# df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500.csv')\n",
    "df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500_5bps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ccaec8f-d4e5-4f21-af4b-e0dde2236a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04',\n",
       "               '2021-06-07', '2021-06-08', '2021-06-09', '2021-06-10',\n",
       "               '2021-06-11', '2021-06-15', '2021-06-16', '2021-06-17',\n",
       "               '2021-06-18', '2021-06-21', '2021-06-22'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.to_datetime(df['date']).value_counts()\n",
    "x.sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13906a66-0521-49f7-a295-cb306fa3f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SP1</th>\n",
       "      <th>SV1</th>\n",
       "      <th>BP1</th>\n",
       "      <th>BV1</th>\n",
       "      <th>SP2</th>\n",
       "      <th>SV2</th>\n",
       "      <th>BP2</th>\n",
       "      <th>BV2</th>\n",
       "      <th>SP3</th>\n",
       "      <th>...</th>\n",
       "      <th>BV3</th>\n",
       "      <th>SP4</th>\n",
       "      <th>SV4</th>\n",
       "      <th>BP4</th>\n",
       "      <th>BV4</th>\n",
       "      <th>SP5</th>\n",
       "      <th>SV5</th>\n",
       "      <th>BP5</th>\n",
       "      <th>BV5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>61</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      SP1   SV1      BP1  BV1      SP2   SV2      BP2   BV2  \\\n",
       "0  2021-06-01  10200.0  3294  10150.0   61  10250.0  2185  10100.0  1240   \n",
       "1  2021-06-01  10200.0  3294  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "2  2021-06-01  10200.0  3324  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "3  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "4  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "\n",
       "       SP3  ...   BV3      SP4   SV4      BP4   BV4      SP5   SV5     BP5  \\\n",
       "0  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "1  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "2  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "3  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "4  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "\n",
       "   BV5  label  \n",
       "0  685      2  \n",
       "1  685      2  \n",
       "2  685      2  \n",
       "3  685      2  \n",
       "4  687      2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = df[pd.to_datetime(df['date']) <= pd.to_datetime('2021-06-07')]\n",
    "test_data = df[pd.to_datetime(df['date']) == pd.to_datetime('2021-06-08')]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f332260a-aaf4-448c-8f0e-4721a0bfe33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  train_set.iloc[:int(np.floor(train_set.shape[0] * 0.8)),:]\n",
    "eval_data = train_set.iloc[int(np.floor(train_set.shape[0] * 0.8)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca1221fa-e2c4-4e88-8b00-590191306b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df,cols,norm):\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[cols])\n",
    "        data = scaler.transform(df[cols])\n",
    "    \n",
    "    \n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(df[cols].abs().max()))\n",
    "        # print(k_len)\n",
    "        data = df[cols]/(10**k_len)\n",
    "\n",
    "    return data,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e258b898-6b75-4a8c-ae7f-6ff4f9ffdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input , scaler = normalize_data(train_data.iloc[:,1:-1],train_data.iloc[:,1:-1].columns,'Z')\n",
    "train_label = train_data.iloc[:,-1].to_numpy()\n",
    "eval_input = scaler.transform(eval_data.iloc[:,1:-1])\n",
    "eval_label = eval_data.iloc[:,-1].to_numpy()\n",
    "test_input = scaler.transform(test_data.iloc[:,1:-1])\n",
    "test_label = test_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0fad0f1-52fc-4f18-be1f-78e1af7a1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "del [train_data,eval_data,df,train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d643863-c46e-4369-81e7-f7e356f780f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data 66.409622\n",
      "82.29984699999997 mb\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "cc=0\n",
    "key=0\n",
    "obj=0\n",
    "for key,obj in locals().items():\n",
    "    cc= sys.getsizeof(obj)/1000000\n",
    "    s+=cc\n",
    "    if cc>20:\n",
    "        print(key,cc)\n",
    "print(s,'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7037675-4984-4f0d-93a5-054b863de147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(eval_input).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3cf944c1-6e08-474f-9d61-4b1b2c827869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LOB(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x,y, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        # self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        # x = prepare_x(data)\n",
    "        # y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        # y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49440fbb-4662-4fc0-846b-54f869298a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    # print(X.shape,T,N,Y.shape)\n",
    "    df = np.array(X)\n",
    "    # print(df.shape)\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b381cdd-3dfd-47b5-aa28-d7249387994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# dataset_train = Dataset_LOB(train_input,train_label, num_classes=3, T=100)\n",
    "# dataset_eval = Dataset_LOB(eval_input,eval_label, num_classes=3, T=100)\n",
    "dataset_test = Dataset_LOB(test_input,test_label, num_classes=3, T=100)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d10459fe-649c-4310-86cc-3e2fc8f290f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([282495, 1, 100, 20]) torch.Size([282495])\n"
     ]
    }
   ],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = torch.utils.data.DataLoader(dataset=dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "print(dataset_test.x.shape, dataset_test.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "23116933-bcb2-40b2-8803-29297466db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3677, -0.2225,  0.3676,  ..., -0.7481,  0.3625,  0.7571],\n",
      "          [ 0.3677, -0.2225,  0.3676,  ..., -0.7481,  0.3625,  0.7555],\n",
      "          [ 0.3677, -0.2228,  0.3676,  ..., -0.7481,  0.3625,  0.7555],\n",
      "          ...,\n",
      "          [ 0.3677, -0.2577,  0.3676,  ..., -0.7457,  0.3625,  0.7535],\n",
      "          [ 0.3677, -0.2577,  0.3676,  ..., -0.7457,  0.3625,  0.7535],\n",
      "          [ 0.3677, -0.2577,  0.3676,  ..., -0.7453,  0.3625,  0.7535]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([1])\n",
      "torch.Size([1, 1, 100, 20]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e000a1e6-b9f6-4aed-9a33-5f70438b7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02a945e4-728f-4927-915f-e9c824efc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,5)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae4304d8-dc78-401a-9883-60a512a4f88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = 3)\n",
    "model.to(mps_device)\n",
    "# device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eaca4b8d-dd64-4a6b-9861-c620472e88ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_60380/1946624102.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_2603_5bps.pt', map_location=mps_device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_30bps.pt', map_location=mps_device))\n",
    "\n",
    "# model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB.pt', map_location=mps_device))\n",
    "model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_2603_5bps.pt', map_location=mps_device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "102e71ca-63e3-46ae-9e1f-cde1ba27b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d4e53f63-9d65-44ea-b964-c170467a06f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5459636453742545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2184    0.4208    0.2875     30509\n",
      "           1     0.8248    0.5816    0.6822    224891\n",
      "           2     0.1627    0.3910    0.2298     27095\n",
      "\n",
      "    accuracy                         0.5460    282495\n",
      "   macro avg     0.4019    0.4645    0.3998    282495\n",
      "weighted avg     0.6958    0.5460    0.5962    282495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "88bfb112-95da-4051-a61c-b8235a2632f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fcf90e2c-4cc6-45ba-ad0b-769f76976185",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = (all_predictions-1)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ab1d2a3-b0a8-4f83-bbda-a99c69f7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPos_Passive(signal):\n",
    "    positions = np.zeros(signal.shape[0]+1)\n",
    "    for i in range(0,len(signal)):\n",
    "        if signal[i]!=0 and signal[i]!= positions[i]:\n",
    "            positions[i+1] = signal[i]\n",
    "        else:\n",
    "            positions[i+1] = positions[i]\n",
    "    return positions[1:]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a507f89e-f51b-4a14-b712-2061019ec18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_passive = getPos_Passive((all_predictions-1)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4913f67a-f97c-4f06-a06f-ac0b8ad892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPos_Aggresive(signal):\n",
    "    positions = np.zeros(signal.shape[0])\n",
    "    positions[0] = signal[0]\n",
    "    for i in range(1,len(signal)):\n",
    "        if signal[i]!=0 and signal[i]!= signal[i-1]:\n",
    "            # print(signal[i],positions[i-1],i,np.sign(signal[i]) == np.sign(positions[i-1]))\n",
    "            if np.sign(signal[i]) == np.sign(positions[i-1]):\n",
    "                positions[i] = positions[i-1]+signal[i]\n",
    "\n",
    "            else:\n",
    "                positions[i] = signal[i]\n",
    "\n",
    "        else:\n",
    "            positions[i] = positions[i-1]\n",
    "            \n",
    "    return positions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a738cf86-8fe9-45d7-9c5c-b8da4d2dcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_aggesive = getPos_Aggresive((all_predictions-1)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a79d3730-62de-4fdd-b002-a86f56097e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(positions_aggesive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9386a6f5-0d1f-4eff-9f3f-03602cadc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePnL_Mid(positions,df,signal):\n",
    "    df['signal'] = signal\n",
    "    df['positions'] = positions\n",
    "    df['entryPrice'] = None\n",
    "    df['exitPrice'] = None\n",
    "    # df['Tick_Ret'] = None\n",
    "    df['midPrice'] = (df['SP1']+df['BP1'])/2\n",
    "    # df['entryMid'] = None\n",
    "\n",
    "    df['isTrade'] = None\n",
    "    df.loc[df['positions']!=df['positions'].shift(1),'isTrade'] = 1\n",
    "    # df.loc[df['positions'].shift(1) > 0 ,'Tick_Ret'] = ((df.loc[df['positions'].shift(1) > 0, 'BP1'] - df['BP1'].shift(1)) / df['BP1'].shift(1))*df['positions'].shift(1)\n",
    "    # df.loc[df['positions'].shift(1) < 0 ,'Tick_Ret'] = ((df.loc[df['positions'].shift(1) < 0, 'SP1'] - df['SP1'].shift(1)) / df['SP1'].shift(1))*df['positions'].shift(1)\n",
    "\n",
    "    df.loc[(df['isTrade']==1) & (df['positions']>0),'entryPrice'] = df.loc[(df['isTrade']==1) & (df['positions']>0),'midPrice']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions']<0),'entryPrice'] = df.loc[(df['isTrade']==1) & (df['positions']<0),'midPrice']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions'].shift(1)>0),'exitPrice'] = df.loc[(df['isTrade']==1) & (df['positions'].shift(1)>0),'midPrice']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions'].shift(1)<0),'exitPrice'] = df.loc[(df['isTrade']==1) & (df['positions'].shift(1)<0),'midPrice']\n",
    "\n",
    "    # df.loc[(df['isTrade']==1),'entryMid'] = df.loc[(df['isTrade']==1),'Mid']\n",
    "    \n",
    "    df['entryPrice'] = df['entryPrice'].ffill()\n",
    "    df['TradeRet'] = np.where(df['isTrade'] == 1, ((df['exitPrice'] - df['entryPrice'].shift(1))/(df['entryPrice'].shift(1)))*df['positions'].shift(1), 0)\n",
    "    df['cumRet'] = (1 + df['TradeRet']).cumprod()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "207ef45a-7e43-4851-ace6-14bd79aa226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePnL_BidAsk(positions,df,signal):\n",
    "    df['signal'] = signal\n",
    "    df['positions'] = positions\n",
    "    df['entryPrice'] = None\n",
    "    df['exitPrice'] = None\n",
    "    # df['Tick_Ret'] = None\n",
    "    df['midPrice'] = (df['SP1']+df['BP1'])/2\n",
    "    # df['midPrice'] = (df['SP1']+df['BP1'])/2\n",
    "    # df['entryMid'] = None\n",
    "\n",
    "    df['isTrade'] = None\n",
    "    df.loc[df['positions']!=df['positions'].shift(1),'isTrade'] = 1\n",
    "    # df.loc[df['positions'].shift(1) > 0 ,'Tick_Ret'] = ((df.loc[df['positions'].shift(1) > 0, 'BP1'] - df['BP1'].shift(1)) / df['BP1'].shift(1))*df['positions'].shift(1)\n",
    "    # df.loc[df['positions'].shift(1) < 0 ,'Tick_Ret'] = ((df.loc[df['positions'].shift(1) < 0, 'SP1'] - df['SP1'].shift(1)) / df['SP1'].shift(1))*df['positions'].shift(1)\n",
    "\n",
    "    df.loc[(df['isTrade']==1) & (df['positions']>0),'entryPrice'] = df.loc[(df['isTrade']==1) & (df['positions']>0),'SP1']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions']<0),'entryPrice'] = df.loc[(df['isTrade']==1) & (df['positions']<0),'BP1']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions'].shift(1)>0),'exitPrice'] = df.loc[(df['isTrade']==1) & (df['positions'].shift(1)>0),'BP1']\n",
    "    df.loc[(df['isTrade']==1) & (df['positions'].shift(1)<0),'exitPrice'] = df.loc[(df['isTrade']==1) & (df['positions'].shift(1)<0),'SP1']\n",
    "\n",
    "    # df.loc[(df['isTrade']==1),'entryMid'] = df.loc[(df['isTrade']==1),'Mid']\n",
    "    \n",
    "    df['entryPrice'] = df['entryPrice'].ffill()\n",
    "    df['TradeRet'] = np.where(df['isTrade'] == 1, ((df['exitPrice'] - df['entryPrice'].shift(1))/(df['entryPrice'].shift(1)))*df['positions'].shift(1), 0)\n",
    "    df['cumRet'] = (1 + df['TradeRet']).cumprod()\n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e4d02d9c-c131-4cba-8eb8-9c3efbe98364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = test_data.reset_index().iloc[99:][['SP1','BP1']]\n",
    "# calculatePnL_BidAsk(positions_passive,df,signal)\n",
    "# df.to_excel('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/pnl_verification.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "815e3ed4-738c-4b9a-9c90-576fec514b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_60380/1016046938.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['entryPrice'] = df['entryPrice'].ffill()\n"
     ]
    }
   ],
   "source": [
    "df = test_data.reset_index().iloc[99:][['SP1','BP1']]\n",
    "calculatePnL_Mid(positions_passive,df,signal)\n",
    "df.to_excel('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/pnl_verification_mid_5bps.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4617a8-33e8-4632-a7a6-ed54a4131cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30a56c-0ff7-4153-9485-3d1fbcc29577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40416875-23b4-43cd-8ac5-3e1d45ee9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = test_data.reset_index().iloc[99:][['SP1','BP1']]\n",
    "# calculatePnL_BidAsk(positions_aggesive,df,signal)\n",
    "# df.to_excel('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/pnl_verification_aggresive.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "152cd0c7-efdc-4976-9115-c1cbd8256247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_60380/1016046938.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['entryPrice'] = df['entryPrice'].ffill()\n"
     ]
    }
   ],
   "source": [
    "df = test_data.reset_index().iloc[99:][['SP1','BP1']]\n",
    "calculatePnL_Mid(positions_aggesive,df,signal)\n",
    "df.to_excel('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/pnl_verification_mid_aggresive_5bps.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e97ba-1c39-4bd6-919e-72b44cd0d070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
