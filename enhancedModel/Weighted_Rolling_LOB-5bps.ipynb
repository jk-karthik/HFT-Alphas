{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239e1ecc-76ea-4351-8d02-fd8e49f0ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d70141-a762-4cdf-86a7-06d2967ecdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.6-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207ed24f-2a28-42e7-9d9c-44825ec1ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500_5bps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66b8195-98b5-4d2e-8772-757fd8a6b7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04',\n",
       "               '2021-06-07', '2021-06-08', '2021-06-09', '2021-06-10',\n",
       "               '2021-06-11', '2021-06-15', '2021-06-16', '2021-06-17',\n",
       "               '2021-06-18', '2021-06-21', '2021-06-22'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.to_datetime(df['date']).value_counts()\n",
    "x.sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b17257e-c52a-4f10-8f07-5c3157f2271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    6138550\n",
       "0     548143\n",
       "2     528647\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce14d37e-127b-4ec5-bdf2-5231df73e7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 548143.,       0.,       0.,       0.,       0., 6138550.,\n",
       "              0.,       0.,       0.,  528647.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a024186c-cb0d-4e93-9fc1-bff1c8382c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SP1</th>\n",
       "      <th>SV1</th>\n",
       "      <th>BP1</th>\n",
       "      <th>BV1</th>\n",
       "      <th>SP2</th>\n",
       "      <th>SV2</th>\n",
       "      <th>BP2</th>\n",
       "      <th>BV2</th>\n",
       "      <th>SP3</th>\n",
       "      <th>...</th>\n",
       "      <th>BV3</th>\n",
       "      <th>SP4</th>\n",
       "      <th>SV4</th>\n",
       "      <th>BP4</th>\n",
       "      <th>BV4</th>\n",
       "      <th>SP5</th>\n",
       "      <th>SV5</th>\n",
       "      <th>BP5</th>\n",
       "      <th>BV5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>61</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      SP1   SV1      BP1  BV1      SP2   SV2      BP2   BV2  \\\n",
       "0  2021-06-01  10200.0  3294  10150.0   61  10250.0  2185  10100.0  1240   \n",
       "1  2021-06-01  10200.0  3294  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "2  2021-06-01  10200.0  3324  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "3  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "4  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "\n",
       "       SP3  ...   BV3      SP4   SV4      BP4   BV4      SP5   SV5     BP5  \\\n",
       "0  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "1  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "2  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "3  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "4  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "\n",
       "   BV5  label  \n",
       "0  685      2  \n",
       "1  685      2  \n",
       "2  685      2  \n",
       "3  685      2  \n",
       "4  687      2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = df[pd.to_datetime(df['date']) <= pd.to_datetime('2021-06-07')]\n",
    "test_data = df[pd.to_datetime(df['date']) == pd.to_datetime('2021-06-08')]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70eec93d-f359-4048-b62f-06ae597d909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  train_set.iloc[:int(np.floor(train_set.shape[0] * 0.8)),:]\n",
    "eval_data = train_set.iloc[int(np.floor(train_set.shape[0] * 0.8)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82db6cd-e81e-48f9-b165-67c499798df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df,cols,norm):\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[cols])\n",
    "        data = scaler.transform(df[cols])\n",
    "    \n",
    "    \n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(df[cols].abs().max()))\n",
    "        # print(k_len)\n",
    "        data = df[cols]/(10**k_len)\n",
    "\n",
    "    return data,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf83fc8-a36c-4962-89e5-6eca81739e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input , scaler = normalize_data(train_data.iloc[:,1:-1],train_data.iloc[:,1:-1].columns,'Z')\n",
    "train_label = train_data.iloc[:,-1].to_numpy()\n",
    "eval_input = scaler.transform(eval_data.iloc[:,1:-1])\n",
    "eval_label = eval_data.iloc[:,-1].to_numpy()\n",
    "test_input = scaler.transform(test_data.iloc[:,1:-1])\n",
    "test_label = test_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a59b93f-6811-40cf-b74a-81bfb028d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "del [train_data,test_data,eval_data,df,train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e609b71b-e723-495f-8143-416301e3accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016139 mb\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "cc=0\n",
    "key=0\n",
    "obj=0\n",
    "for key,obj in locals().items():\n",
    "    cc= sys.getsizeof(obj)/1000000\n",
    "    s+=cc\n",
    "    if cc>20:\n",
    "        print(key,cc)\n",
    "print(s,'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b33332-52b9-43cd-8afd-018c407a0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(eval_input).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936f3082-0355-4624-bc82-4ed20765fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LOB(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x,y, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        # self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        # x = prepare_x(data)\n",
    "        # y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        # y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d8957d-6f1c-49e7-8585-b0ff7c90b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    # print(X.shape,T,N,Y.shape)\n",
    "    df = np.array(X)\n",
    "    # print(df.shape)\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4667b7-6626-431b-b847-f2967943f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_train = Dataset_LOB(train_input,train_label, num_classes=3, T=100)\n",
    "dataset_eval = Dataset_LOB(eval_input,eval_label, num_classes=3, T=100)\n",
    "dataset_test = Dataset_LOB(test_input,test_label, num_classes=3, T=100)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3df8efa9-6ddf-43c7-a3d6-4cb494c1e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1732671, 1, 100, 20]) torch.Size([282495])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "print(dataset_train.x.shape, dataset_test.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a79388be-355e-4d40-9ee0-40391dfe055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1264,  0.4584,  0.1254,  ...,  1.3163,  0.1117, -0.2681],\n",
      "          [ 0.1264,  0.4584,  0.1254,  ...,  1.3163,  0.1117, -0.2681],\n",
      "          [ 0.1264,  0.4584,  0.1254,  ...,  1.3163,  0.1117, -0.2681],\n",
      "          ...,\n",
      "          [ 0.1264,  0.4537,  0.1254,  ...,  1.3157,  0.1117, -0.2676],\n",
      "          [ 0.1264,  0.4541,  0.1254,  ...,  1.3157,  0.1117, -0.2676],\n",
      "          [ 0.1264,  0.4541,  0.1254,  ...,  1.3157,  0.1117, -0.2676]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([1])\n",
      "torch.Size([1, 1, 100, 20]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0ced532-6f99-42ce-8841-b4ee7cdd385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d42530-5935-4573-8479-e4a169b60889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,5)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ec1dd9f-003c-418f-bd01-247a4d87dcba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(mps_device)\n",
    "# device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa41ab58-2ace-469b-9372-82fa6bd509f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a6235f4-c67e-43d8-a020-f89c5b196a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = Counter(train_label)\n",
    "class_weights = torch.Tensor([len(train_label)/c for c in pd.Series(class_count).sort_index().values])\n",
    "class_weights = class_weights.to(device)  \n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9d8a68-3cda-4b45-a8d2-d8621b506282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.5874,  1.2226, 11.4138], device='mps:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b1242eb-548c-4944-a6ca-983ad62a5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=1, path='./model.pt'):\n",
    "        self.patience = patience\n",
    "        self.path= path\n",
    "        self.counter = 0\n",
    "        self.best_score = np.inf\n",
    "        self.early_stop = False\n",
    "        self.best_test_epoch = 0\n",
    "        \n",
    "    def __call__(self, val_loss, model,it):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.best_test_epoch = it\n",
    "    \n",
    "        elif val_loss > self.best_score:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True \n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "            self.best_test_epoch = it\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8161e5e7-5d31-464f-b7c7-4de37ed217c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_2603_5bps.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e6118d7-186d-4c2d-b51f-c570925021db",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "        patience=15, \n",
    "        path=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffbeb67c-858b-49a5-ac19-298ae1835dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        early_stopping(test_loss,model,it)\n",
    "        if early_stopping.early_stop:\n",
    "            print('Patience Exhausted')\n",
    "            break\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(dt)\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {early_stopping.best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140584f-c80b-478c-accc-74ba6caf9e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 1/50 [27:21<22:20:44, 1641.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:21.710431\n",
      "Epoch 1/50, Train Loss: 0.7918,           Validation Loss: 1.0318, Duration: 0:27:21.710431, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 2/50 [55:34<22:17:19, 1671.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:28:12.591237\n",
      "Epoch 2/50, Train Loss: 0.7226,           Validation Loss: 1.0074, Duration: 0:28:12.591237, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▏                                  | 3/50 [1:22:46<21:35:28, 1653.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:12.541398\n",
      "Epoch 3/50, Train Loss: 0.6988,           Validation Loss: 1.0118, Duration: 0:27:12.541398, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▉                                  | 4/50 [1:50:25<21:09:21, 1655.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:38.542965\n",
      "Epoch 4/50, Train Loss: 0.6829,           Validation Loss: 1.0075, Duration: 0:27:38.542965, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▋                                 | 5/50 [2:17:53<20:39:43, 1652.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:28.169845\n",
      "Epoch 5/50, Train Loss: 0.6756,           Validation Loss: 1.0062, Duration: 0:27:28.169845, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▍                                | 6/50 [2:45:21<20:10:59, 1651.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:28.165076\n",
      "Epoch 6/50, Train Loss: 0.6706,           Validation Loss: 1.0010, Duration: 0:27:28.165076, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▏                               | 7/50 [3:12:46<19:41:52, 1649.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:24.481381\n",
      "Epoch 7/50, Train Loss: 0.6634,           Validation Loss: 1.0117, Duration: 0:27:24.481381, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████▉                               | 8/50 [3:40:10<19:13:21, 1647.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:24.485839\n",
      "Epoch 8/50, Train Loss: 0.6576,           Validation Loss: 0.9728, Duration: 0:27:24.485839, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▋                              | 9/50 [4:07:42<18:46:48, 1648.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:31.870882\n",
      "Epoch 9/50, Train Loss: 0.6559,           Validation Loss: 0.9843, Duration: 0:27:31.870882, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▏                            | 10/50 [4:35:10<18:19:03, 1648.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:27.663105\n",
      "Epoch 10/50, Train Loss: 0.6511,           Validation Loss: 0.9778, Duration: 0:27:27.663105, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████▉                            | 11/50 [5:02:43<17:52:33, 1650.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:33.524354\n",
      "Epoch 11/50, Train Loss: 0.6488,           Validation Loss: 1.0031, Duration: 0:27:33.524354, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████▋                           | 12/50 [5:30:19<17:26:03, 1651.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:35.278311\n",
      "Epoch 12/50, Train Loss: 0.6479,           Validation Loss: 0.9789, Duration: 0:27:35.278311, Best Val Epoch: 7\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1513c27-eba1-4f61-9c46-fd0ba9aa78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping.best_test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac4716-ccc0-494b-ae95-4d309b252bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e5157d-c57a-492f-ae99-0a2712d5f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfede7a1-b79a-4070-823e-eaf41b227fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_60065/2158610274.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_2603_5bps.pt', map_location=mps_device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(mps_device)\n",
    "model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_2603_5bps.pt', map_location=mps_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09b6ff-4848-4420-83ae-0491a56f5974",
   "metadata": {},
   "source": [
    "# Training with adjusted class frequncy weighted loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d810f9f-4554-4925-96c1-fd11adba0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5460\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c9bf9f-af36-482c-8a34-6034cace1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5459636453742545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2184    0.4208    0.2875     30509\n",
      "           1     0.8248    0.5816    0.6822    224891\n",
      "           2     0.1627    0.3910    0.2298     27095\n",
      "\n",
      "    accuracy                         0.5460    282495\n",
      "   macro avg     0.4019    0.4645    0.3998    282495\n",
      "weighted avg     0.6958    0.5460    0.5962    282495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d67ab74-2ca1-4b6f-bcb6-3e46e89e6291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12838,  14909,   2762],\n",
       "       [ 42328, 130800,  51763],\n",
       "       [  3625,  12876,  10594]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(all_targets,all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90289d8-3ce8-46dd-8117-7d0272f12e8d",
   "metadata": {},
   "source": [
    "# Train data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0762401-8f41-4d0a-954f-27c64b8cd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8624\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4f83558-a641-4292-9dc9-4ed95151d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8624164656764036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5838    0.9531    0.7241    163602\n",
      "           1     0.9932    0.8415    0.9111   1417281\n",
      "           2     0.5503    0.9603    0.6996    151788\n",
      "\n",
      "    accuracy                         0.8624   1732671\n",
      "   macro avg     0.7091    0.9183    0.7783   1732671\n",
      "weighted avg     0.9158    0.8624    0.8749   1732671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4412d14-1454-4d5e-8575-57152e3ec93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 155927,    4856,    2819],\n",
       "       [ 108388, 1192602,  116291],\n",
       "       [   2774,    3259,  145755]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(all_targets,all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b9c84-0df2-44d6-98fb-e9eab8b8c155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd93aed-ac91-4157-9d4e-9a093ea6b3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ad178-d06f-4387-be02-c124987e0333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
