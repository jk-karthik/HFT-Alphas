{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239e1ecc-76ea-4351-8d02-fd8e49f0ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d70141-a762-4cdf-86a7-06d2967ecdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.6-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207ed24f-2a28-42e7-9d9c-44825ec1ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500_30bps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66b8195-98b5-4d2e-8772-757fd8a6b7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04',\n",
       "               '2021-06-07', '2021-06-08', '2021-06-09', '2021-06-10',\n",
       "               '2021-06-11', '2021-06-15', '2021-06-16', '2021-06-17',\n",
       "               '2021-06-18', '2021-06-21', '2021-06-22'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.to_datetime(df['date']).value_counts()\n",
    "x.sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a024186c-cb0d-4e93-9fc1-bff1c8382c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SP1</th>\n",
       "      <th>SV1</th>\n",
       "      <th>BP1</th>\n",
       "      <th>BV1</th>\n",
       "      <th>SP2</th>\n",
       "      <th>SV2</th>\n",
       "      <th>BP2</th>\n",
       "      <th>BV2</th>\n",
       "      <th>SP3</th>\n",
       "      <th>...</th>\n",
       "      <th>BV3</th>\n",
       "      <th>SP4</th>\n",
       "      <th>SV4</th>\n",
       "      <th>BP4</th>\n",
       "      <th>BV4</th>\n",
       "      <th>SP5</th>\n",
       "      <th>SV5</th>\n",
       "      <th>BP5</th>\n",
       "      <th>BV5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>61</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      SP1   SV1      BP1  BV1      SP2   SV2      BP2   BV2  \\\n",
       "0  2021-06-01  10200.0  3294  10150.0   61  10250.0  2185  10100.0  1240   \n",
       "1  2021-06-01  10200.0  3294  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "2  2021-06-01  10200.0  3324  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "3  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "4  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "\n",
       "       SP3  ...   BV3      SP4   SV4      BP4   BV4      SP5   SV5     BP5  \\\n",
       "0  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "1  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "2  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "3  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "4  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "\n",
       "   BV5  label  \n",
       "0  685      1  \n",
       "1  685      1  \n",
       "2  685      1  \n",
       "3  685      1  \n",
       "4  687      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = df[pd.to_datetime(df['date']) <= pd.to_datetime('2021-06-07')]\n",
    "test_data = df[pd.to_datetime(df['date']) == pd.to_datetime('2021-06-08')]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70eec93d-f359-4048-b62f-06ae597d909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  train_set.iloc[:int(np.floor(train_set.shape[0] * 0.8)),:]\n",
    "eval_data = train_set.iloc[int(np.floor(train_set.shape[0] * 0.8)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82db6cd-e81e-48f9-b165-67c499798df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df,cols,norm):\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[cols])\n",
    "        data = scaler.transform(df[cols])\n",
    "    \n",
    "    \n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(df[cols].abs().max()))\n",
    "        # print(k_len)\n",
    "        data = df[cols]/(10**k_len)\n",
    "\n",
    "    return data,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf83fc8-a36c-4962-89e5-6eca81739e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input , scaler = normalize_data(train_data.iloc[:,1:-1],train_data.iloc[:,1:-1].columns,'Z')\n",
    "train_label = train_data.iloc[:,-1].to_numpy()\n",
    "eval_input = scaler.transform(eval_data.iloc[:,1:-1])\n",
    "eval_label = eval_data.iloc[:,-1].to_numpy()\n",
    "test_input = scaler.transform(test_data.iloc[:,1:-1])\n",
    "test_label = test_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a59b93f-6811-40cf-b74a-81bfb028d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "del [train_data,test_data,eval_data,df,train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e609b71b-e723-495f-8143-416301e3accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015917 mb\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "cc=0\n",
    "key=0\n",
    "obj=0\n",
    "for key,obj in locals().items():\n",
    "    cc= sys.getsizeof(obj)/1000000\n",
    "    s+=cc\n",
    "    if cc>20:\n",
    "        print(key,cc)\n",
    "print(s,'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b33332-52b9-43cd-8afd-018c407a0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(eval_input).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936f3082-0355-4624-bc82-4ed20765fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LOB(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x,y, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        # self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        # x = prepare_x(data)\n",
    "        # y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        # y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d8957d-6f1c-49e7-8585-b0ff7c90b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    # print(X.shape,T,N,Y.shape)\n",
    "    df = np.array(X)\n",
    "    # print(df.shape)\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4667b7-6626-431b-b847-f2967943f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_train = Dataset_LOB(train_input,train_label, num_classes=3, T=100)\n",
    "dataset_eval = Dataset_LOB(eval_input,eval_label, num_classes=3, T=100)\n",
    "dataset_test = Dataset_LOB(test_input,test_label, num_classes=3, T=100)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df8efa9-6ddf-43c7-a3d6-4cb494c1e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1732671, 1, 100, 20]) torch.Size([282495])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "print(dataset_train.x.shape, dataset_test.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79388be-355e-4d40-9ee0-40391dfe055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.8504, -0.9396,  0.8519,  ...,  0.0262,  0.8641,  0.2516],\n",
      "          [ 0.8504, -0.9396,  0.8519,  ...,  0.0262,  0.8641,  0.2516],\n",
      "          [ 0.8504, -0.9396,  0.8519,  ...,  0.0262,  0.8641,  0.2516],\n",
      "          ...,\n",
      "          [ 0.8504, -0.7872,  0.8519,  ...,  0.0262,  0.8641,  0.2516],\n",
      "          [ 0.8504, -0.7869,  0.8519,  ...,  0.0262,  0.8641,  0.2516],\n",
      "          [ 0.8504, -0.8168,  0.8519,  ...,  0.0262,  0.8641,  0.2516]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([1])\n",
      "torch.Size([1, 1, 100, 20]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0ced532-6f99-42ce-8841-b4ee7cdd385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d42530-5935-4573-8479-e4a169b60889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,5)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ec1dd9f-003c-418f-bd01-247a4d87dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(mps_device)\n",
    "# device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa41ab58-2ace-469b-9372-82fa6bd509f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a6235f4-c67e-43d8-a020-f89c5b196a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = Counter(train_label)\n",
    "class_weights = torch.Tensor([len(train_label)/c for c in pd.Series(class_count).sort_index().values])\n",
    "class_weights = class_weights.to(device)  \n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea9d8a68-3cda-4b45-a8d2-d8621b506282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.9862,  1.0569, 38.3458], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b1242eb-548c-4944-a6ca-983ad62a5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=1, path='./model.pt'):\n",
    "        self.patience = patience\n",
    "        self.path= path\n",
    "        self.counter = 0\n",
    "        self.best_score = np.inf\n",
    "        self.early_stop = False\n",
    "        self.best_test_epoch = 0\n",
    "        \n",
    "    def __call__(self, val_loss, model,it):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.best_test_epoch = it\n",
    "    \n",
    "        elif val_loss > self.best_score:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True \n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "            self.best_test_epoch = it\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8161e5e7-5d31-464f-b7c7-4de37ed217c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_30bps.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e6118d7-186d-4c2d-b51f-c570925021db",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "        patience=7, \n",
    "        path=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbeb67c-858b-49a5-ac19-298ae1835dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        early_stopping(test_loss,model,it)\n",
    "        if early_stopping.early_stop:\n",
    "            print('Patience Exhausted')\n",
    "            break\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(dt)\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {early_stopping.best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f140584f-c80b-478c-accc-74ba6caf9e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 1/25 [26:14<10:29:42, 1574.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:26:14.269653\n",
      "Epoch 1/25, Train Loss: 0.8045,           Validation Loss: 0.8274, Duration: 0:26:14.269653, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                    | 2/25 [53:08<10:12:31, 1597.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:26:54.391658\n",
      "Epoch 2/25, Train Loss: 0.7295,           Validation Loss: 0.8515, Duration: 0:26:54.391658, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▌                                 | 3/25 [1:20:07<9:49:25, 1607.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:26:58.983422\n",
      "Epoch 3/25, Train Loss: 0.7017,           Validation Loss: 0.8437, Duration: 0:26:58.983422, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 4/25 [1:47:23<9:26:32, 1618.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:15.791928\n",
      "Epoch 4/25, Train Loss: 0.6841,           Validation Loss: 0.8225, Duration: 0:27:15.791928, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 5/25 [2:14:20<8:59:21, 1618.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:26:56.960251\n",
      "Epoch 5/25, Train Loss: 0.6736,           Validation Loss: 0.8235, Duration: 0:26:56.960251, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████                             | 6/25 [2:41:20<8:32:39, 1618.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:00.491928\n",
      "Epoch 6/25, Train Loss: 0.6661,           Validation Loss: 0.7997, Duration: 0:27:00.491928, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▋                           | 7/25 [3:08:33<8:06:59, 1623.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:12.259285\n",
      "Epoch 7/25, Train Loss: 0.6584,           Validation Loss: 0.7931, Duration: 0:27:12.259285, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▏                         | 8/25 [3:35:44<7:40:37, 1625.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:10.950670\n",
      "Epoch 8/25, Train Loss: 0.6544,           Validation Loss: 0.8471, Duration: 0:27:10.950670, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████▋                        | 9/25 [4:03:06<7:14:53, 1630.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:22.120872\n",
      "Epoch 9/25, Train Loss: 0.6497,           Validation Loss: 0.7719, Duration: 0:27:22.120872, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████▊                      | 10/25 [4:30:20<6:47:58, 1631.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:14.126046\n",
      "Epoch 10/25, Train Loss: 0.6473,           Validation Loss: 0.7835, Duration: 0:27:14.126046, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████▎                    | 11/25 [4:57:29<6:20:35, 1631.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:09.420243\n",
      "Epoch 11/25, Train Loss: 0.6432,           Validation Loss: 0.8186, Duration: 0:27:09.420243, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████▊                   | 12/25 [5:24:49<5:53:59, 1633.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:20.037610\n",
      "Epoch 12/25, Train Loss: 0.6392,           Validation Loss: 0.7919, Duration: 0:27:20.037610, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████▏                 | 13/25 [5:52:07<5:27:01, 1635.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:17.956780\n",
      "Epoch 13/25, Train Loss: 0.6364,           Validation Loss: 0.8003, Duration: 0:27:17.956780, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████▋                | 14/25 [6:19:29<5:00:08, 1637.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:21.893698\n",
      "Epoch 14/25, Train Loss: 0.6346,           Validation Loss: 0.7890, Duration: 0:27:21.893698, Best Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▏              | 15/25 [6:46:49<4:33:00, 1638.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:20.059679\n",
      "Epoch 15/25, Train Loss: 0.6316,           Validation Loss: 0.7708, Duration: 0:27:20.059679, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████▋             | 16/25 [7:14:07<4:05:40, 1637.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:17.319141\n",
      "Epoch 16/25, Train Loss: 0.6282,           Validation Loss: 0.7838, Duration: 0:27:17.319141, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▏           | 17/25 [7:41:25<3:38:23, 1637.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:18.276994\n",
      "Epoch 17/25, Train Loss: 0.6272,           Validation Loss: 0.7783, Duration: 0:27:18.276994, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████▋          | 18/25 [8:08:45<3:11:10, 1638.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:20.081642\n",
      "Epoch 18/25, Train Loss: 0.6264,           Validation Loss: 0.7727, Duration: 0:27:20.081642, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████         | 19/25 [8:36:06<2:43:54, 1639.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:20.472621\n",
      "Epoch 19/25, Train Loss: 0.6242,           Validation Loss: 0.7809, Duration: 0:27:20.472621, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████▌       | 20/25 [9:03:33<2:16:48, 1641.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:27.504365\n",
      "Epoch 20/25, Train Loss: 0.6229,           Validation Loss: 0.7635, Duration: 0:27:27.504365, Best Val Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████      | 21/25 [9:30:53<1:49:24, 1641.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:20.015649\n",
      "Epoch 21/25, Train Loss: 0.6220,           Validation Loss: 0.7647, Duration: 0:27:20.015649, Best Val Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████▌    | 22/25 [9:58:33<1:22:20, 1646.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:39.860612\n",
      "Epoch 22/25, Train Loss: 0.6208,           Validation Loss: 0.7817, Duration: 0:27:39.860612, Best Val Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████▋    | 22/25 [10:16:11<1:24:01, 1680.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m batch_gd(model, criterion, optimizer, \n\u001b[1;32m      2\u001b[0m                                     train_loader, val_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 20\u001b[0m, in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"about to get model output\")\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(\"done getting model output\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[18], line 75\u001b[0m, in \u001b[0;36mdeeplob.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     73\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 75\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1513c27-eba1-4f61-9c46-fd0ba9aa78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping.best_test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac4716-ccc0-494b-ae95-4d309b252bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b85bc5-0275-4a92-b976-3a738cd653a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96771ba4-b836-47c6-a18a-14a97ea3b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e5157d-c57a-492f-ae99-0a2712d5f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfede7a1-b79a-4070-823e-eaf41b227fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_94672/40889344.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_30bps.pt', map_location=mps_device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/fast-alphas/best_val_roLOB_30bps.pt', map_location=mps_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09b6ff-4848-4420-83ae-0491a56f5974",
   "metadata": {},
   "source": [
    "# Training with adjusted class frequncy weighted loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d810f9f-4554-4925-96c1-fd11adba0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.6893\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c9bf9f-af36-482c-8a34-6034cace1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.689318395015841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0794    0.3257    0.1276     10760\n",
      "           1     0.9424    0.7152    0.8132    262937\n",
      "           2     0.0819    0.3611    0.1335      8798\n",
      "\n",
      "    accuracy                         0.6893    282495\n",
      "   macro avg     0.3679    0.4673    0.3581    282495\n",
      "weighted avg     0.8827    0.6893    0.7659    282495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d67ab74-2ca1-4b6f-bcb6-3e46e89e6291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3505,   6239,   1016],\n",
       "       [ 40301, 188047,  34589],\n",
       "       [   358,   5263,   3177]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(all_targets,all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf196a7f-0340-468c-bfb5-b9ff4f69226b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b90289d8-3ce8-46dd-8117-7d0272f12e8d",
   "metadata": {},
   "source": [
    "# Train data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0762401-8f41-4d0a-954f-27c64b8cd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8945\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4f83558-a641-4292-9dc9-4ed95151d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8944854504981038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3534    0.9700    0.5181     48093\n",
      "           1     0.9982    0.8901    0.9411   1639390\n",
      "           2     0.3166    0.9725    0.4776     45188\n",
      "\n",
      "    accuracy                         0.8945   1732671\n",
      "   macro avg     0.5561    0.9442    0.6456   1732671\n",
      "weighted avg     0.9625    0.8945    0.9172   1732671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4412d14-1454-4d5e-8575-57152e3ec93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  46648,    1444,       1],\n",
       "       [  85257, 1459254,   94879],\n",
       "       [     75,    1166,   43947]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(all_targets,all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b9c84-0df2-44d6-98fb-e9eab8b8c155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31111793-a3e9-41a4-b02c-a4fa8ff773d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8009\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    # Move to GPU\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9533a8d-ca20-433a-b428-a6541a3db8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8009185072986464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1453    0.2947    0.1946     19166\n",
      "           1     0.9171    0.8586    0.8869    391548\n",
      "           2     0.1823    0.2252    0.2015     22380\n",
      "\n",
      "    accuracy                         0.8009    433094\n",
      "   macro avg     0.4149    0.4595    0.4277    433094\n",
      "weighted avg     0.8450    0.8009    0.8208    433094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd93aed-ac91-4157-9d4e-9a093ea6b3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
